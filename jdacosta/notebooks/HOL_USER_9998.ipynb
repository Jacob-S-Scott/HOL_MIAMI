{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b875b6f",
   "metadata": {},
   "source": [
    "# Miami Hands-On Lab: Snowflake Intelligence for Builders\n",
    "\n",
    "---\n",
    "\n",
    "**üìÖ Date:** Thursday, October 16, 2025 | 04:00 PM ET  \n",
    "**üìç Location:** The LAB Miami, 2750 NW 3rd Ave, Suite 24, Miami, FL 33127\n",
    "\n",
    "**üéØ Event Focus:** Interactive hands-on lab exploring Snowflake Cortex Intelligence capabilities\n",
    "\n",
    "---\n",
    "\n",
    "### üë• Presented By\n",
    "\n",
    "**Atalia Horenshtien** - Senior Consultant, AI Engineering | Hakkoda, an IBM Company [atalia.horenshtien@ibm.com](mailto:atalia.horenshtien@ibm.com)\n",
    "**Jacob Scott** - Senior Consultant, AI Engineering | Hakkoda, an IBM Company [jacob.scott@ibm.com](mailto:jacob.scott@ibm.com)\n",
    "**John DaCosta** - Senior Solution Engineer | Snowflake [john.dacosta@snowflake.com](mailto:john.dacosta@snowflake.com)\n",
    "\n",
    "### ü§ù In Partnership With\n",
    "\n",
    "**Snowflake** and **Hakkoda, an IBM Company**\n",
    "\n",
    "---\n",
    "\n",
    "### üìö What You'll Learn\n",
    "\n",
    "In this guided session, we'll walk you step-by-step through how to use Snowflake Intelligence for tangible business outcomes:\n",
    "- Setting up your environment and connecting to live data\n",
    "- Applying AI-powered features that surface insights faster\n",
    "- Building Cortex Agents with RAG (Retrieval-Augmented Generation)\n",
    "- Creating semantic models for natural language querying\n",
    "- Integrating custom tools and external data sources\n",
    "\n",
    "You'll leave with practical \"how-to\" skills, a repeatable framework, and the confidence to unlock intelligence from your own data with Snowflake and Hakkoda.\n",
    "\n",
    "---\n",
    "\n",
    "**üîó Event Information:** [Miami Hands-On Lab Details](https://www.snowflake.com/event/miami-hands-on-lab-snowflake-intelligence-for-builders-20251016/)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d5cd1",
   "metadata": {},
   "source": [
    "### üìö Snowflake Python Libraries Import\n",
    "\n",
    "**What:** This cell imports essential Python libraries for working with Snowflake's advanced features including the Snowpark API and Core API.\n",
    "\n",
    "**Why:** These libraries enable programmatic interaction with Snowflake, allowing you to:\n",
    "- Create and manage Snowflake objects using the Core API (`snowflake.core`)\n",
    "- Execute dataframe operations using Snowpark (`snowflake.snowpark`)\n",
    "- Handle JSON data and work with DataFrames for data analysis\n",
    "\n",
    "**How:** The imports provide access to:\n",
    "- `json` - Parse JSON responses from Snowflake functions\n",
    "- `pandas` - Data manipulation and analysis\n",
    "- `snowflake.core.Root` - Entry point for Snowflake Core API to manage objects\n",
    "- `snowflake.snowpark.Session` - Create Snowpark sessions for distributed computing\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [Snowflake Python API Reference](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/index)\n",
    "- [Snowpark Developer Guide](https://docs.snowflake.com/en/developer-guide/snowpark/python/index)\n",
    "- [Snowflake Core API](https://docs.snowflake.com/en/developer-guide/snowflake-python-api/snowflake-python-overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa4eb6-2042-4d43-9c61-fb18cc9aef48",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from snowflake.core import Root\n",
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676932f-19ee-4012-a540-2543bbe99ee4",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "# HOL Setup Notebook\n",
    "Run the following commands to provision the necessary objects for the Snowflake Intelligence HOL\n",
    "\n",
    "- add snowflake package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d2233c-e24d-4234-9d49-3dd3a6e28f52",
   "metadata": {
    "collapsed": false,
    "name": "cell4"
   },
   "source": [
    "## Setup User Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884054ec",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Schema Setup and Configuration\n",
    "\n",
    "**What:** This cell sets up a personalized schema for each user within the HOL (Hands-On Lab) database using dynamic schema naming.\n",
    "\n",
    "**Why:** \n",
    "- Creates isolated workspaces for multiple users in a shared training environment\n",
    "- Uses the `IDENTIFIER()` function to dynamically create schemas based on the current user's name\n",
    "- Prevents naming conflicts and allows each user to work independently\n",
    "\n",
    "**How:** The code executes the following steps:\n",
    "1. **USE ROLE HOL_ADMIN** - Switches to the administrator role with appropriate permissions\n",
    "2. **SET CURRENT_USER = CURRENT_USER()** - Stores the logged-in username in a session variable\n",
    "3. **USE DATABASE HOL** - Sets the working database context\n",
    "4. **CREATE SCHEMA IF NOT EXISTS IDENTIFIER($CURRENT_USER)** - Creates a schema named after the user (e.g., if username is \"JOHN_DOE\", creates schema \"JOHN_DOE\")\n",
    "\n",
    "The `IDENTIFIER()` function treats the variable value as an object identifier, enabling dynamic object creation.\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [CREATE SCHEMA](https://docs.snowflake.com/en/sql-reference/sql/create-schema)\n",
    "- [IDENTIFIER Function](https://docs.snowflake.com/en/sql-reference/identifier-literal)\n",
    "- [Session Variables](https://docs.snowflake.com/en/sql-reference/session-variables)\n",
    "- [USE ROLE](https://docs.snowflake.com/en/sql-reference/sql/use-role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "SCHEMA_SETUP"
   },
   "outputs": [],
   "source": [
    "USE ROLE HOL_ADMIN;\n",
    "\n",
    "SET CURRENT_USER = CURRENT_USER();\n",
    "\n",
    "USE DATABASE HOL;\n",
    "CREATE SCHEMA IF NOT EXISTS IDENTIFIER($CURRENT_USER);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a96a3",
   "metadata": {},
   "source": [
    "### üìÇ Set Working Schema Context\n",
    "\n",
    "**What:** This cell sets the active schema to your personal user schema for all subsequent operations.\n",
    "\n",
    "**Why:** \n",
    "- Establishes the working context so all tables, views, and objects are created in your personal schema\n",
    "- Eliminates the need to fully qualify object names in subsequent queries\n",
    "- Ensures isolation between different users' work in the HOL environment\n",
    "\n",
    "**How:** The `USE SCHEMA IDENTIFIER($CURRENT_USER)` command switches the session context to the schema created in the previous step, using the same dynamic identifier approach.\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [USE SCHEMA](https://docs.snowflake.com/en/sql-reference/sql/use-schema)\n",
    "- [Understanding Name Resolution](https://docs.snowflake.com/en/sql-reference/name-resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a6c3e-00cd-4d8d-b08f-468f49226c32",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "WORK_IN_OWN_SCHEMA"
   },
   "outputs": [],
   "source": [
    "USE SCHEMA IDENTIFIER($CURRENT_USER);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fa26e-6c47-4ae9-8b59-a8e3d54a4a61",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "## Setup Unstructured Chunks Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3907a5",
   "metadata": {},
   "source": [
    "### ü§ñ Document Parsing and Text Chunking with AI\n",
    "\n",
    "**What:** This cell performs intelligent document processing by:\n",
    "1. Creating a table to store chunked text from documents\n",
    "2. Using AI-powered OCR to extract text from PDF documents\n",
    "3. Splitting extracted text into manageable chunks for semantic search\n",
    "\n",
    "**Why:** \n",
    "- **Document Intelligence**: Converts unstructured PDF documents into searchable text using AI\n",
    "- **Retrieval-Augmented Generation (RAG)**: Chunking enables efficient semantic search for RAG applications\n",
    "- **Optimal Chunk Size**: 500-character chunks balance context preservation with search precision\n",
    "- **Scalability**: Processes multiple documents from a stage automatically\n",
    "\n",
    "**How:** The process involves four key steps:\n",
    "\n",
    "1. **Create Table**: Defines schema for storing document chunks with metadata\n",
    "   - `document_name` - Identifier for the source document\n",
    "   - `chunk_id` - Index of the chunk within the document\n",
    "   - `chunk_text` - The actual text content (max 500 chars)\n",
    "   - `document_date` - Extracted date from document filename\n",
    "\n",
    "2. **AI_PARSE_DOCUMENT**: Snowflake's AI-powered OCR function\n",
    "   - Reads PDFs from the `@DATA.SEC_FILINGS_STAGE` \n",
    "   - `'mode': 'OCR'` - Uses optical character recognition for text extraction\n",
    "   - `'page_split': false` - Keeps document as a single text block\n",
    "   - Extracts text into the `:content` field\n",
    "\n",
    "3. **SPLIT_TEXT_RECURSIVE_CHARACTER**: Cortex function for intelligent chunking\n",
    "   - Splits long documents into 500-character segments\n",
    "   - Preserves semantic meaning by respecting word boundaries\n",
    "   - Returns an array of text chunks\n",
    "\n",
    "4. **FLATTEN**: Converts array of chunks into rows for table storage\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [AI_PARSE_DOCUMENT Function](https://docs.snowflake.com/en/user-guide/snowflake-cortex/document-ai/ai-parse-document)\n",
    "- [SPLIT_TEXT_RECURSIVE_CHARACTER](https://docs.snowflake.com/en/sql-reference/functions/split_text_recursive_character)\n",
    "- [FLATTEN Table Function](https://docs.snowflake.com/en/sql-reference/functions/flatten)\n",
    "- [Document AI Overview](https://docs.snowflake.com/en/user-guide/snowflake-cortex/document-ai/document-ai-overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659a194-5dbc-457e-b33e-ac1a96cbb0c0",
   "metadata": {
    "language": "sql",
    "name": "CREATE_TABLE_FOR_CHUNKS_OF_TEXT"
   },
   "outputs": [],
   "source": [
    "\n",
    "-- CREATE OR REPLACE TABLE SEC_FILINGS_CHUNKS (\n",
    "CREATE TABLE IF NOT EXISTS SEC_FILINGS_CHUNKS (\n",
    "    document_name varchar,\n",
    "    chunk_id varchar,\n",
    "    chunk_text varchar,\n",
    "    document_date date\n",
    ");\n",
    "\n",
    "-- Perform OCR and Chunk Text\n",
    "INSERT INTO SEC_FILINGS_CHUNKS  \n",
    "    with doc_text as (\n",
    "        select\n",
    "            split_part(relative_path,'.',0) as document_name,\n",
    "            AI_PARSE_DOCUMENT (\n",
    "                TO_FILE('@DATA.SEC_FILINGS_STAGE',relative_path),\n",
    "                {'mode': 'OCR' , 'page_split': false}\n",
    "            ):content::varchar as doc_text,\n",
    "            to_date(split_part(document_name,'_',3),'MM-DD-YY') as doc_date\n",
    "        from directory('@DATA.SEC_FILINGS_STAGE')\n",
    "    )\n",
    "    \n",
    "    , chunked as (\n",
    "        select \n",
    "            document_name,\n",
    "            SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER (\n",
    "              doc_text,\n",
    "              'none',\n",
    "              500\n",
    "            ) as chunks,\n",
    "            doc_date\n",
    "        from doc_text\n",
    "    )\n",
    "    \n",
    "    , flattened as (\n",
    "        select\n",
    "            document_name,\n",
    "            index as chunk_id,\n",
    "            value::varchar as chunk_text,\n",
    "            doc_date\n",
    "        from chunked,\n",
    "            TABLE(FLATTEN(INPUT => CHUNKS))\n",
    "    )\n",
    "    \n",
    "    SELECT * FROM flattened\n",
    ";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a9cd6b",
   "metadata": {},
   "source": [
    "### üîç Verify Chunked Document Data\n",
    "\n",
    "**What:** This cell queries the SEC_FILINGS_CHUNKS table to examine the parsed and chunked document data.\n",
    "\n",
    "**Why:** \n",
    "- Validates that documents were successfully processed\n",
    "- Inspects the structure and quality of chunked text\n",
    "- Confirms that metadata (document names, dates, chunk IDs) was correctly extracted\n",
    "\n",
    "**How:** Simple SELECT statement retrieves all records from the table, showing the complete dataset of processed document chunks.\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [SELECT Statement](https://docs.snowflake.com/en/sql-reference/sql/select)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1a8d7-2b95-4472-9a2e-3c79de4b3d15",
   "metadata": {
    "language": "sql",
    "name": "EXAMINE_CHUNK_DATA"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM SEC_FILINGS_CHUNKS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be197b9b-e87c-4b21-8b09-44b1fe527615",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "## Create Search Service for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc18298",
   "metadata": {},
   "source": [
    "### üîé Create Cortex Search Service for Semantic Search\n",
    "\n",
    "**What:** This cell creates a Cortex Search Service that enables semantic (meaning-based) search over the chunked documents and tests it with a sample query.\n",
    "\n",
    "**Why:** \n",
    "- **Semantic Search**: Unlike keyword search, finds results based on meaning and context\n",
    "- **RAG Foundation**: Essential component for Retrieval-Augmented Generation workflows\n",
    "- **Vector Search**: Automatically creates embeddings for similarity search\n",
    "- **Real-time Updates**: `TARGET_LAG` parameter keeps the index synchronized with table changes\n",
    "- **Agent Integration**: Cortex Agents can use this service as a tool to retrieve relevant information\n",
    "\n",
    "**How:** The process has two parts:\n",
    "\n",
    "1. **CREATE CORTEX SEARCH SERVICE**:\n",
    "   - `SEC_FILINGS_SEARCH` - Name of the search service\n",
    "   - `ON CHUNK_TEXT` - The column containing text to be indexed and searched\n",
    "   - `ATTRIBUTES DOCUMENT_DATE` - Additional filterable metadata columns\n",
    "   - `WAREHOUSE = SNOWFLAKE_LEARNING_WH` - Compute resources for indexing\n",
    "   - `TARGET_LAG = '7 DAYS'` - Maximum staleness for index updates\n",
    "   - `AS (SELECT * FROM SEC_FILINGS_CHUNKS)` - Source data for the index\n",
    "\n",
    "2. **Test Query**: The SEARCH_PREVIEW function demonstrates semantic search:\n",
    "   - Searches for \"NVIDIA revenue guidance\" (natural language query)\n",
    "   - Returns top 5 most relevant chunks with metadata\n",
    "   - Results ranked by semantic similarity, not keyword matching\n",
    "   - Returns JSON with matching document names, chunk IDs, dates, and text\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [Cortex Search Service](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/cortex-search-overview)\n",
    "- [CREATE CORTEX SEARCH SERVICE](https://docs.snowflake.com/en/sql-reference/sql/create-cortex-search-service)\n",
    "- [SEARCH_PREVIEW Function](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/query-cortex-search-service)\n",
    "- [Semantic Search Concepts](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/cortex-search-overview#how-cortex-search-works)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28493b-d0b5-4d0b-853f-dcea35749a58",
   "metadata": {
    "language": "sql",
    "name": "CREATE_CORTEX_SEARCH_SERVICE"
   },
   "outputs": [],
   "source": [
    "\n",
    "CREATE CORTEX SEARCH SERVICE IF NOT EXISTS SEC_FILINGS_SEARCH\n",
    "  ON CHUNK_TEXT\n",
    "  ATTRIBUTES DOCUMENT_DATE\n",
    "  WAREHOUSE = SNOWFLAKE_LEARNING_WH\n",
    "  TARGET_LAG = '7 DAYS'\n",
    "  AS (SELECT * FROM SEC_FILINGS_CHUNKS);\n",
    "\n",
    "-- RUN A SAMPLE QUERY\n",
    "SELECT PARSE_JSON(\n",
    "  SNOWFLAKE.CORTEX.SEARCH_PREVIEW(\n",
    "    'SEC_FILINGS_SEARCH',\n",
    "    '{\n",
    "      \"query\": \"NVIDIA revenue guidance\",\n",
    "      \"columns\": [\"DOCUMENT_NAME\", \"CHUNK_ID\", \"DOCUMENT_DATE\", \"CHUNK_TEXT\"],\n",
    "      \"limit\": 5\n",
    "    }'\n",
    "  )\n",
    ")['results'] AS results;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17767969-a908-470d-a900-2c09da97d9de",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "## Create a Custom Tool for the Agent\n",
    "Just a dummy stock price tool, in reality this could easily be replaced with an API call using an external access integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81d5ac",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Create Custom Tool (Stored Procedure) for Agent\n",
    "\n",
    "**What:** This cell creates a stored procedure that serves as a custom tool for the Cortex Agent, simulating a stock price lookup function.\n",
    "\n",
    "**Why:** \n",
    "- **Agent Extensibility**: Demonstrates how to extend agent capabilities with custom functions\n",
    "- **External Integration Pattern**: Shows the structure for tools that could call external APIs\n",
    "- **Function Calling**: Cortex Agents can automatically detect when to call this tool based on user queries\n",
    "- **Prototype/Demo**: This dummy implementation returns a fixed value, but in production could:\n",
    "  - Call external APIs via External Access Integrations\n",
    "  - Query real-time data feeds\n",
    "  - Integrate with market data providers\n",
    "\n",
    "**How:** The procedure is defined with:\n",
    "- **Parameters**:\n",
    "  - `TICKER STRING` - Stock ticker symbol (e.g., \"NVDA\", \"AAPL\")\n",
    "  - `EXCHANGE STRING` - Stock exchange identifier (e.g., \"NYSE\", \"NASDAQ\")\n",
    "- **Returns**: FLOAT - Stock price value\n",
    "- **Language**: SQL (could also be Python, JavaScript, Java)\n",
    "- **Logic**: Currently returns hardcoded value (185.88) for demonstration\n",
    "- **Test Call**: Executes the procedure with sample parameters ('nvda', 'nyse')\n",
    "\n",
    "**When added to a Cortex Agent**, the agent will:\n",
    "1. Understand when users ask about stock prices\n",
    "2. Automatically call this function with appropriate parameters\n",
    "3. Incorporate the results into its response\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [CREATE PROCEDURE](https://docs.snowflake.com/en/sql-reference/sql/create-procedure)\n",
    "- [Stored Procedures Overview](https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-overview)\n",
    "- [Cortex Agent Custom Tools](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst/cortex-analyst-tools)\n",
    "- [External Access Integration](https://docs.snowflake.com/en/developer-guide/external-network-access/external-network-access-overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e410619-0d8c-41b7-87a9-897337893a08",
   "metadata": {
    "language": "sql",
    "name": "CREATE_CUSTOM_TOOL"
   },
   "outputs": [],
   "source": [
    "-- Dummy Tool\n",
    "CREATE OR REPLACE PROCEDURE GET_STOCK_PRICE(TICKER STRING, EXCHANGE STRING)\n",
    "RETURNS FLOAT\n",
    "LANGUAGE SQL\n",
    "AS\n",
    "$$\n",
    "DECLARE\n",
    "    stock_price FLOAT;\n",
    "BEGIN\n",
    "    stock_price := 185.88;\n",
    "    RETURN stock_price;\n",
    "END;\n",
    "$$;\n",
    "\n",
    "call get_stock_price('nvda','nyse');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83dc052-ce86-46a7-ae27-f7eae63b5362",
   "metadata": {
    "collapsed": false,
    "name": "cell8"
   },
   "source": [
    "## Verify Existing Price History Data\n",
    "For structured data we will be using a preloaded table made available for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5953f",
   "metadata": {},
   "source": [
    "### üìä Clone Price History Data Table\n",
    "\n",
    "**What:** This cell creates a personal copy of the stock price history table using Snowflake's zero-copy cloning feature.\n",
    "\n",
    "**Why:** \n",
    "- **Instant Copy**: Creates a full copy without duplicating storage or waiting for data transfer\n",
    "- **Data Isolation**: Each user gets their own table they can modify without affecting others\n",
    "- **Zero Storage Cost (Initially)**: Only stores differences when data is modified\n",
    "- **Time Travel**: Clones preserve the source table's history\n",
    "- **Test Environment**: Safe environment to experiment with data transformations\n",
    "\n",
    "**How:** \n",
    "- **CLONE** keyword creates a metadata copy pointing to the same data\n",
    "- Source: `DATA.STOCK_PRICE_HISTORY` (shared reference table)\n",
    "- Target: `STOCK_PRICE_HISTORY` (in your personal schema)\n",
    "- **OR REPLACE** ensures a clean slate if run multiple times\n",
    "\n",
    "The cloned table contains historical OHLCV data:\n",
    "- Date, Ticker symbol\n",
    "- Open, High, Low, Close prices\n",
    "- Volume, Dividends, Stock splits\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [CREATE TABLE ... CLONE](https://docs.snowflake.com/en/sql-reference/sql/create-clone)\n",
    "- [Zero-Copy Cloning](https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables)\n",
    "- [Understanding Table Cloning](https://docs.snowflake.com/en/user-guide/object-clone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df421e8e-a3ee-483b-a162-a4074366b313",
   "metadata": {
    "language": "sql",
    "name": "CREATE_OWN_PRICE_HISTORY_DATA"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE STOCK_PRICE_HISTORY CLONE DATA.STOCK_PRICE_HISTORY;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363798e",
   "metadata": {},
   "source": [
    "### üìà Examine Stock Price History Data\n",
    "\n",
    "**What:** This cell queries and displays the stock price history data to verify the clone was successful.\n",
    "\n",
    "**Why:** \n",
    "- Validates that the table contains the expected data\n",
    "- Previews the data structure and content\n",
    "- Helps understand what data is available for semantic model creation\n",
    "\n",
    "**How:** Simple SELECT statement retrieves all records from the STOCK_PRICE_HISTORY table, showing historical OHLCV (Open, High, Low, Close, Volume) data with dividends and stock splits.\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [Querying Data in Snowflake](https://docs.snowflake.com/en/user-guide/querying-data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f792b0-e4a7-494b-b457-c6f8f0cce4d1",
   "metadata": {
    "language": "sql",
    "name": "EXAMINE_PRICE_HISTORY_DATA"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM STOCK_PRICE_HISTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c411b-4ce4-44f4-aee1-1cfca51e7868",
   "metadata": {
    "collapsed": false,
    "name": "cell10"
   },
   "source": [
    "## Create the Semantic View\n",
    "\n",
    "This could also be done a number of different ways, mainly through Snowsight. If you have YAML already provisioned in this case you can simply use the system function as shown below.\n",
    "\n",
    "NOTE: Make sure to change schema and database in the yaml below before creation to HOL.<YOUR_USER>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd0d8b0",
   "metadata": {},
   "source": [
    "### üß† Create Semantic Model for Natural Language Queries\n",
    "\n",
    "**What:** This cell creates a semantic view that enables natural language querying of stock price data using Cortex Analyst.\n",
    "\n",
    "**Why:** \n",
    "- **Natural Language to SQL**: Users can ask questions in plain English instead of writing SQL\n",
    "- **Business Context**: Adds meaning to data through descriptions, synonyms, and custom instructions\n",
    "- **Cortex Analyst Integration**: Powers the Cortex Analyst tool that agents use to query structured data\n",
    "- **Verified Queries**: Provides examples that improve query generation accuracy\n",
    "- **Data Governance**: Centralizes business logic and metrics definitions\n",
    "\n",
    "**How:** The YAML semantic model defines:\n",
    "\n",
    "**1. Model Metadata:**\n",
    "- Name and description of the semantic model\n",
    "- Custom instructions for query interpretation (default filters, rounding, return calculations)\n",
    "\n",
    "**2. Table Definition:**\n",
    "- Maps logical \"stock_prices\" to physical `STOCK_PRICE_HISTORY` table\n",
    "- ‚ö†Ô∏è **NOTE**: Update `schema: jacob_scott` to your username\n",
    "\n",
    "**3. Time Dimensions:**\n",
    "- `date` - Trading date with synonyms like \"trading date\", \"day\"\n",
    "\n",
    "**4. Dimensions (Categorical Data):**\n",
    "- `ticker` - Stock symbol (NVDA, AAPL, MSFT) marked as enum for better query planning\n",
    "\n",
    "**5. Facts (Measurable Values):**\n",
    "- Price data: open_price, high_price, low_price, close_price\n",
    "- Trading data: volume, dividends, stock_splits\n",
    "- Each with synonyms for natural language understanding\n",
    "\n",
    "**6. Metrics (Aggregations):**\n",
    "- `avg_close_price` - Average closing price over period\n",
    "- `max_close_price` - Record high close\n",
    "- `min_close_price` - Lowest close\n",
    "- `total_volume` - Cumulative shares traded\n",
    "\n",
    "**7. Filters (Reusable Predicates):**\n",
    "- `last_30_days` - Past month filter\n",
    "- `last_year` - Past 365 days filter\n",
    "\n",
    "**8. Verified Queries (Training Examples):**\n",
    "- Example questions with validated SQL\n",
    "- Improves accuracy for similar questions\n",
    "\n",
    "**Example Questions This Enables:**\n",
    "- \"What was the average closing price for NVDA last month?\"\n",
    "- \"Show me the highest price for AAPL this year\"\n",
    "- \"How much volume traded for MSFT in the last 30 days?\"\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [Cortex Analyst Semantic Model](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst/semantic-model-spec)\n",
    "- [SYSTEM$CREATE_SEMANTIC_VIEW_FROM_YAML](https://docs.snowflake.com/en/sql-reference/functions/system_create_semantic_view_from_yaml)\n",
    "- [Cortex Analyst Overview](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst)\n",
    "- [Semantic Model Best Practices](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst/semantic-model-spec#label-semantic-model-best-practices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8356ec-230d-4dbf-8540-68e21bcf246c",
   "metadata": {
    "language": "sql",
    "name": "CREATE_SEMANTIC_VIEW"
   },
   "outputs": [],
   "source": [
    "CALL SYSTEM$CREATE_SEMANTIC_VIEW_FROM_YAML(\n",
    "  'HOL.' || $CURRENT_USER,\n",
    "  $$\n",
    "name: stock_prices_semantic_model\n",
    "description: Semantic model for historical daily stock prices (OHLCV) with dividends and splits.\n",
    "custom_instructions: >\n",
    "  If the user doesn't specify a date filter, apply a default filter for the last year.\n",
    "  Round numeric outputs to 2 decimal places.\n",
    "  If the user asks for 'returns' or 'change', interpret as percentage change over\n",
    "  the selected period (e.g., (last_close - first_close) / first_close * 100).\n",
    "\n",
    "tables:\n",
    "  - name: stock_prices\n",
    "    description: Daily OHLCV per ticker.\n",
    "    base_table:\n",
    "      database: HOL\n",
    "      schema: jacob_scott\n",
    "      table: STOCK_PRICE_HISTORY\n",
    "\n",
    "    time_dimensions:\n",
    "      - name: date\n",
    "        synonyms: [\"trading date\", \"day\"]\n",
    "        description: Trading day (no time component).\n",
    "        expr: DATE\n",
    "        data_type: DATE\n",
    "        unique: false\n",
    "\n",
    "    dimensions:\n",
    "      - name: ticker\n",
    "        synonyms: [\"symbol\"]\n",
    "        description: Stock ticker symbol (e.g., NVDA).\n",
    "        expr: TICKER\n",
    "        data_type: TEXT\n",
    "        unique: false\n",
    "        is_enum: true\n",
    "\n",
    "    facts:\n",
    "      - name: open_price\n",
    "        synonyms: [\"open\"]\n",
    "        description: Opening price for the day.\n",
    "        expr: OPEN_PRICE\n",
    "        data_type: NUMBER\n",
    "\n",
    "      - name: high_price\n",
    "        synonyms: [\"high\"]\n",
    "        description: Intraday high price.\n",
    "        expr: HIGH_PRICE\n",
    "        data_type: NUMBER\n",
    "\n",
    "      - name: low_price\n",
    "        synonyms: [\"low\"]\n",
    "        description: Intraday low price.\n",
    "        expr: LOW_PRICE\n",
    "        data_type: NUMBER\n",
    "\n",
    "      - name: close_price\n",
    "        synonyms: [\"close\", \"closing price\"]\n",
    "        description: Closing price for the day.\n",
    "        expr: CLOSE_PRICE\n",
    "        data_type: NUMBER\n",
    "\n",
    "      - name: volume\n",
    "        synonyms: [\"shares traded\"]\n",
    "        description: Number of shares traded during the day.\n",
    "        expr: VOLUME\n",
    "        data_type: NUMBER\n",
    "\n",
    "      - name: dividends\n",
    "        synonyms: [\"dividend\"]\n",
    "        description: Cash dividends paid on the day.\n",
    "        expr: DIVIDENDS\n",
    "        data_type: NUMBER\n",
    "\n",
    "      - name: stock_splits\n",
    "        synonyms: [\"split ratio\"]\n",
    "        description: Stock split ratio for the day (e.g., 4.0 == 4-for-1).\n",
    "        expr: STOCK_SPLITS\n",
    "        data_type: NUMBER\n",
    "\n",
    "    metrics:\n",
    "      - name: avg_close_price\n",
    "        synonyms: [\"average close\"]\n",
    "        description: Average closing price over the selected period.\n",
    "        expr: AVG(CLOSE_PRICE)\n",
    "\n",
    "      - name: max_close_price\n",
    "        synonyms: [\"record close\", \"all-time high close\"]\n",
    "        description: Maximum closing price over the selected period.\n",
    "        expr: MAX(CLOSE_PRICE)\n",
    "\n",
    "      - name: min_close_price\n",
    "        synonyms: [\"lowest close\"]\n",
    "        description: Minimum closing price over the selected period.\n",
    "        expr: MIN(CLOSE_PRICE)\n",
    "\n",
    "      - name: total_volume\n",
    "        synonyms: [\"sum volume\", \"trading volume\"]\n",
    "        description: Total shares traded over the selected period.\n",
    "        expr: SUM(VOLUME)\n",
    "\n",
    "    filters:\n",
    "      - name: last_30_days\n",
    "        synonyms: [\"past month\"]\n",
    "        description: Filter to the last 30 calendar days.\n",
    "        expr: \"DATE >= DATEADD('day', -30, CURRENT_DATE())\"\n",
    "\n",
    "      - name: last_year\n",
    "        synonyms: [\"past year\", \"last 12 months\"]\n",
    "        description: Filter to the last 365 days.\n",
    "        expr: \"DATE >= DATEADD('day', -365, CURRENT_DATE())\"\n",
    "\n",
    "verified_queries:\n",
    "  - name: average_close_by_month\n",
    "    question: What was the average closing price by month for NVDA this year?\n",
    "    sql: >\n",
    "      SELECT DATE_TRUNC('month', DATE) AS month,\n",
    "             AVG(CLOSE_PRICE) AS avg_close\n",
    "      FROM SNOWFLAKE_INTELIGENCE_HOL.DATA.STOCK_PRICE_HISTORY\n",
    "      WHERE TICKER = 'NVDA'\n",
    "        AND DATE >= DATE_TRUNC('year', CURRENT_DATE())\n",
    "      GROUP BY 1\n",
    "      ORDER BY 1\n",
    "\n",
    "  - name: total_volume_last_30_days\n",
    "    question: How many shares traded for AAPL in the last 30 days?\n",
    "    sql: >\n",
    "      SELECT SUM(VOLUME) AS total_volume\n",
    "      FROM SNOWFLAKE_INTELIGENCE_HOL.DATA.STOCK_PRICE_HISTORY\n",
    "      WHERE TICKER = 'AAPL'\n",
    "        AND DATE >= DATEADD('day', -30, CURRENT_DATE())\n",
    "  $$\n",
    "  -- Omit third parameter or set to FALSE to create the view\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca859d0",
   "metadata": {},
   "source": [
    "### üîç Test Cortex Search on Snowflake Documentation\n",
    "\n",
    "**What:** This cell demonstrates querying a public Cortex Search Service containing Snowflake's official documentation.\n",
    "\n",
    "**Why:** \n",
    "- **Live Example**: Shows how to query an existing Cortex Search Service\n",
    "- **Documentation Search**: Access to searchable Snowflake documentation database\n",
    "- **Pattern Template**: Demonstrates the query structure for your own search services\n",
    "- **JSON Response**: Shows how search results are returned and structured\n",
    "\n",
    "**How:** \n",
    "- Queries the `SNOWFLAKE_DOCUMENTATION.SHARED.CKE_SNOWFLAKE_DOCS_SERVICE` search service\n",
    "- Natural language query: \"how do i configure a default schema for a snowflake user account\"\n",
    "- Requests 3 types of information:\n",
    "  - `chunk` - The text content containing the answer\n",
    "  - `document_title` - Title of the documentation page\n",
    "  - `source_url` - Link to the full documentation\n",
    "- Limits to top 10 results\n",
    "- Returns results as JSON array in the `results` field\n",
    "\n",
    "**Use Case:** This public search service can help agents answer Snowflake technical questions by retrieving relevant documentation.\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [Cortex Search SEARCH_PREVIEW](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/query-cortex-search-service)\n",
    "- [Query Cortex Search Service](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/query-cortex-search-service#using-sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7b3ae-2b22-4c9b-be7e-ff65f280f43f",
   "metadata": {
    "language": "sql",
    "name": "TEST_SEARCH_SQL"
   },
   "outputs": [],
   "source": [
    "SELECT PARSE_JSON(\n",
    "  SNOWFLAKE.CORTEX.SEARCH_PREVIEW(\n",
    "      'SNOWFLAKE_DOCUMENTATION.SHARED.CKE_SNOWFLAKE_DOCS_SERVICE',\n",
    "      '{\n",
    "        \"query\": \"how do i configure a default schema for a snowflake user account\",\n",
    "        \"columns\":[\n",
    "            \"chunk\",\n",
    "            \"document_title\",\n",
    "            \"source_url\"\n",
    "        ],\n",
    "        \"limit\":10\n",
    "      }'\n",
    "  )\n",
    ")['results'] as results\n",
    ";\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f384b52",
   "metadata": {},
   "source": [
    "### üêç Parse SQL Search Results into Python\n",
    "\n",
    "**What:** This cell converts the SQL query results from the previous cell into a pandas DataFrame for easier manipulation in Python.\n",
    "\n",
    "**Why:** \n",
    "- **Python Integration**: Enables Python-based data analysis on search results\n",
    "- **Snowflake Notebooks**: Demonstrates the `cells` API that references other cell outputs\n",
    "- **DataFrame Format**: Makes results easier to process, filter, and visualize\n",
    "\n",
    "**How:** \n",
    "- Uses `cells.TEST_SEARCH_SQL` to reference the previous SQL cell's output\n",
    "- Calls `.to_pandas()` to convert Snowflake results to a pandas DataFrame\n",
    "- Result contains the JSON search results in the `RESULTS` column\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [Using Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-develop-run)\n",
    "- [Cell References in Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-develop-run#referencing-cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dcb3d2-265a-4758-8d36-7cbbd7b5994b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "PARSE_SQL_SEARCH_RESULT"
   },
   "outputs": [],
   "source": [
    " \n",
    "result = cells.TEST_SEARCH_SQL.to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39b8b5",
   "metadata": {},
   "source": [
    "### üëÅÔ∏è Display Raw Search Results\n",
    "\n",
    "**What:** This cell displays the raw DataFrame containing the search results.\n",
    "\n",
    "**Why:** \n",
    "- **Data Inspection**: View the structure of the returned data\n",
    "- **Debugging**: Verify the JSON is properly formatted\n",
    "- **Understanding Output**: See how Snowflake packages search results\n",
    "\n",
    "**How:** Simply outputs the `result` DataFrame variable, which Snowflake Notebooks automatically renders as a formatted table.\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [Displaying Data in Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-develop-run#displaying-output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d8192-e2d1-4294-a8cd-03d755355eae",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "RAW_CELL_OUTPUT"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ceef56",
   "metadata": {},
   "source": [
    "### üîÑ Convert JSON Search Results to Structured DataFrame\n",
    "\n",
    "**What:** This cell parses the JSON search results and converts them into a structured pandas DataFrame with columns for each field.\n",
    "\n",
    "**Why:** \n",
    "- **Structured Access**: Converts nested JSON into tabular format with named columns\n",
    "- **Analysis Ready**: Makes it easy to filter, sort, and analyze search results\n",
    "- **Column-based Access**: Access individual fields like `df['chunk']` or `df['source_url']`\n",
    "\n",
    "**How:** \n",
    "- `json.loads()` - Parses the JSON string from the first row's RESULTS column\n",
    "- `pd.DataFrame()` - Converts the JSON array into a DataFrame\n",
    "- Result has columns: `chunk`, `document_title`, `source_url`, and relevance scores\n",
    "\n",
    "**Example Output Structure:**\n",
    "```\n",
    "| chunk | document_title | source_url | score |\n",
    "|-------|---------------|------------|-------|\n",
    "| text  | doc name      | https://... | 0.95 |\n",
    "```\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)\n",
    "- [Working with JSON in Python](https://docs.python.org/3/library/json.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a11920-3fe9-4ebc-9dae-86820b84a37e",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "CONVERT_SEARCH_RESULT_TO_DATAFRAME"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(json.loads(result[\"RESULTS\"][0]))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d0a745-b0cc-4817-b850-cb82cf9b936e",
   "metadata": {
    "collapsed": false,
    "name": "CORTEX_REST_API_DOCS_LINK"
   },
   "source": [
    "[Query Cortex Search REST API](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/query-cortex-search-service#rest-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e22e87b-1561-4e5a-a7e8-5b3f13373e27",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "TEST_SEARCH_PYTHON"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0a00a9e",
   "metadata": {},
   "source": [
    "### üåê Cortex Search via REST API (Python Implementation)\n",
    "\n",
    "**What:** This cell is a placeholder for implementing Cortex Search queries using the REST API from Python code.\n",
    "\n",
    "**Why:** \n",
    "- **Alternative Access Method**: REST API allows querying Cortex Search from external applications\n",
    "- **Integration**: Enables calling Cortex Search from web apps, microservices, or external Python scripts\n",
    "- **Authentication**: Uses OAuth or JWT tokens for secure access\n",
    "- **Programmatic Access**: Useful for building custom applications that need search functionality\n",
    "\n",
    "**How:** To implement, you would:\n",
    "1. Create a `CortexSearchService` object using the Core API\n",
    "2. Call the `.search()` method with your query\n",
    "3. Process the returned results\n",
    "\n",
    "**Example Implementation:**\n",
    "```python\n",
    "from snowflake.core import Root\n",
    "root = Root(session)\n",
    "search_service = root.databases[\"HOL\"].schemas[session.get_current_schema()].cortex_search_services[\"SEC_FILINGS_SEARCH\"]\n",
    "\n",
    "response = search_service.search(\n",
    "    query=\"NVIDIA revenue guidance\",\n",
    "    columns=[\"DOCUMENT_NAME\", \"CHUNK_TEXT\"],\n",
    "    limit=5\n",
    ")\n",
    "```\n",
    "\n",
    "**üìñ Documentation:**\n",
    "- [Query Cortex Search REST API](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/query-cortex-search-service#rest-api)\n",
    "- [Snowflake Python API for Cortex Search](https://docs.snowflake.com/en/developer-guide/snowflake-python-api/snowflake-python-cortex-search)\n",
    "- [REST API Authentication](https://docs.snowflake.com/en/developer-guide/sql-api/authenticating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977c199-9949-4182-a87a-08fce4a3d636",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "## Configure Cortex Agent\n",
    "\n",
    "Now that we have all the pieces in place for the agent to pull context from, it's time to create the agent. The rest of the process will be done in Snowsight. Follow the steps below to complete the agent creation.\n",
    "\n",
    "\n",
    "### Step-by-Step Guide\n",
    "1. Create the Agent \n",
    "    - Go to AI & ML > Agents\n",
    "    - Select \"Create Agent\"\n",
    "    - Enter agent name and description\n",
    "2. Add Cortex Search Service\n",
    "    - Select \"Tools\" > \"Cortex Search Services\" > \"+ Add\"\n",
    "    - Select your existing Cortex Search service\n",
    "    - Enter chunk_id as ID column and document_name as title column.\n",
    "    - Enter name and description for the search service\n",
    "    - Click \"Add\"\n",
    "3. Add Cortex Analyst Tool (Using Semantic Model)\n",
    "    - Select \"Tools\" > \"Cortex Analyst\" > \"+ Add\"\n",
    "    - Enter name for the semantic model tool\n",
    "    - Select the semantic view\n",
    "    - Choose warehouse for query execution\n",
    "    - Set query timeout (seconds)\n",
    "    - Add description\n",
    "    - Click \"Add\"\n",
    "4. Add Custom Tools\n",
    "    - Select \"Tools\" > \"Custom Tools\" > \"+ Add\"\n",
    "    - Leave resource type as procedure\n",
    "    - Select existing stored procedure\n",
    "    - Configure parameters (name, type, description, required status)\n",
    "    - Select warehouse for execution (leave as default)\n",
    "    - Add tool description and optionally argument descriptions\n",
    "    - Click \"Add\"\n",
    "5. Add Custom Prompt/Instructions\n",
    "    - In the agent configuration, add custom instructions for:\n",
    "        * Response behavior\n",
    "        * Orchestration logic\n",
    "        * System prompts\n",
    "6. Save and Test\n",
    "    - Click \"Save\" to create the agent\n",
    "    - Test with sample questions\n",
    "    - Monitor agent performance and user feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c2b69-2773-4a12-9f1d-57028a6fff73",
   "metadata": {
    "name": "cell7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73b097e2-f2d2-4db1-b357-ce0abea03269",
   "metadata": {
    "name": "cell9"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "",
   "authorId": "7513526462763",
   "authorName": "HOL_USER_99",
   "lastEditTime": 1760624275172,
   "notebookId": "od2obobfn7o6zkn4aimg",
   "sessionId": "3778a8c1-b1b0-4d22-bcd2-ded9a6c1c27a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
