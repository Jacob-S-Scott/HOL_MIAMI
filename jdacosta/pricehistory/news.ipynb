{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stock News Retrieval Test\n",
        "\n",
        "This notebook tests retrieving the latest news for a given stock ticker from the yfinance API.\n",
        "\n",
        "Uses the existing `StockDataDownloader` class from `app.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the stock data downloader\n",
        "from app import StockDataDownloader\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Clear any cached imports to ensure we get the latest version\n",
        "import importlib\n",
        "import sys\n",
        "if 'app' in sys.modules:\n",
        "    importlib.reload(sys.modules['app'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:05,707 - app - INFO - Initialized StockDataDownloader with base path: data/price-history\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ StockDataDownloader initialized\n"
          ]
        }
      ],
      "source": [
        "# Initialize the downloader\n",
        "downloader = StockDataDownloader()\n",
        "print(\"✓ StockDataDownloader initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ticker: NVDA\n",
            "Max news items: 10\n"
          ]
        }
      ],
      "source": [
        "# Configure the ticker and max news items\n",
        "ticker = \"NVDA\"  # Change this to any ticker you want\n",
        "max_news_items = 10  # Number of news items to retrieve\n",
        "\n",
        "print(f\"Ticker: {ticker}\")\n",
        "print(f\"Max news items: {max_news_items}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RAW NEWS DATA INSPECTION FOR NVDA\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:06,309 - app - INFO - Fetching recent news for NVDA (attempt 1/3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Found 10 news items\n",
            "\n",
            "First news item structure:\n",
            "--------------------------------------------------------------------------------\n",
            "id: 4731fc11-ab62-444a-af68-cddf98eca95e\n",
            "content: {'id': '4731fc11-ab62-444a-af68-cddf98eca95e', 'contentType': 'STORY', 'title': \"AMD CEO Lisa Su says AI critics are 'thinking too small' after massive OpenAI deal\", 'description': '', 'summary': 'The chipmaker inked a multi-gigawatt GPU agreement with OpenAI, setting the stage for a potential 10-year AI supercycle', 'pubDate': '2025-10-06T20:28:18Z', 'displayTime': '2025-10-06T20:28:19Z', 'isHosted': True, 'bypassModal': False, 'previewUrl': None, 'thumbnail': {'originalUrl': 'https://s.yimg.com/os/creatr-uploaded-images/2025-10/8b3d5a70-a2f0-11f0-bff3-5539b367b53e', 'originalWidth': 6000, 'originalHeight': 4015, 'caption': '', 'resolutions': [{'url': 'https://s.yimg.com/uu/api/res/1.2/oaGTChmBk9av.dDIWPZEjw--~B/aD00MDE1O3c9NjAwMDthcHBpZD15dGFjaHlvbg--/https://s.yimg.com/os/creatr-uploaded-images/2025-10/8b3d5a70-a2f0-11f0-bff3-5539b367b53e', 'width': 6000, 'height': 4015, 'tag': 'original'}, {'url': 'https://s.yimg.com/uu/api/res/1.2/PxX7uqUOkGCwsrjbk3QimA--~B/Zmk9c3RyaW07aD0xMjg7dz0xNzA7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2025-10/8b3d5a70-a2f0-11f0-bff3-5539b367b53e', 'width': 170, 'height': 128, 'tag': '170x128'}]}, 'provider': {'displayName': 'Yahoo Finance', 'url': 'http://finance.yahoo.com/'}, 'canonicalUrl': {'url': 'https://finance.yahoo.com/news/amd-ceo-lisa-su-says-ai-critics-are-thinking-too-small-after-massive-openai-deal-202818700.html', 'site': 'finance', 'region': 'US', 'lang': 'en-US'}, 'clickThroughUrl': {'url': 'https://finance.yahoo.com/news/amd-ceo-lisa-su-says-ai-critics-are-thinking-too-small-after-massive-openai-deal-202818700.html', 'site': 'finance', 'region': 'US', 'lang': 'en-US'}, 'metadata': {'editorsPick': True}, 'finance': {'premiumFinance': {'isPremiumNews': False, 'isPremiumFreeNews': False}}, 'storyline': {'storylineItems': [{'content': {'id': 'e2ef311c-2eb8-46ba-953e-effaa53d1f31', 'contentType': 'STORY', 'isHosted': True, 'title': 'AMD stock rockets higher on multibillion-dollar OpenAI deal', 'thumbnail': {'originalUrl': 'https://s.yimg.com/os/creatr-uploaded-images/2023-07/e9ad9880-23cd-11ee-bbfe-716b58f596df', 'originalWidth': 5060, 'originalHeight': 3367, 'caption': '', 'resolutions': None}, 'provider': {'displayName': 'Yahoo Finance', 'sourceId': 'yahoofinance.com'}, 'previewUrl': None, 'providerContentUrl': '', 'canonicalUrl': {'url': 'https://finance.yahoo.com/news/amd-stock-rockets-higher-on-multibillion-dollar-openai-deal-125503782.html'}, 'clickThroughUrl': {'url': 'https://finance.yahoo.com/news/amd-stock-rockets-higher-on-multibillion-dollar-openai-deal-125503782.html'}}}, {'content': {'id': 'b82e1bb0-c648-45a8-a533-c14de3038edf', 'contentType': 'STORY', 'isHosted': True, 'title': \"Stock market today: S&P 500, Nasdaq notch record close as AMD's OpenAI deal sparks wild rally\", 'thumbnail': {'originalUrl': 'https://s.yimg.com/os/creatr-uploaded-images/2025-10/5b474fb0-9fc1-11f0-bfb4-6397842a3388', 'originalWidth': 6048, 'originalHeight': 4032, 'caption': '', 'resolutions': None}, 'provider': {'displayName': 'Yahoo Finance', 'sourceId': 'yahoofinance.com'}, 'previewUrl': None, 'providerContentUrl': '', 'canonicalUrl': {'url': 'https://finance.yahoo.com/news/live/stock-market-today-sp-500-nasdaq-notch-record-close-as-amds-openai-deal-sparks-wild-rally-200238236.html'}, 'clickThroughUrl': {'url': 'https://finance.yahoo.com/news/live/stock-market-today-sp-500-nasdaq-notch-record-close-as-amds-openai-deal-sparks-wild-rally-200238236.html'}}}]}}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "NOW FETCHING USING StockDataDownloader\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:06,518 - app - INFO - Successfully fetched 10 news items for NVDA\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Successfully retrieved 10 news items\n"
          ]
        }
      ],
      "source": [
        "# First, let's inspect the raw news data structure from yfinance\n",
        "import yfinance as yf\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"RAW NEWS DATA INSPECTION FOR {ticker}\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "stock = yf.Ticker(ticker)\n",
        "raw_news = stock.news\n",
        "\n",
        "if raw_news:\n",
        "    print(f\"✓ Found {len(raw_news)} news items\\n\")\n",
        "    \n",
        "    # Show the structure of the first news item\n",
        "    if len(raw_news) > 0:\n",
        "        print(\"First news item structure:\")\n",
        "        print(\"-\" * 80)\n",
        "        for key, value in raw_news[0].items():\n",
        "            if key == 'content':\n",
        "                print(f\"{key}: [NESTED CONTENT - see below]\")\n",
        "                # Show the content structure\n",
        "                content = value\n",
        "                print(\"  Content fields:\")\n",
        "                for ckey, cvalue in content.items():\n",
        "                    if isinstance(cvalue, str) and len(cvalue) > 100:\n",
        "                        print(f\"    {ckey}: {cvalue[:100]}...\")\n",
        "                    else:\n",
        "                        print(f\"    {ckey}: {cvalue}\")\n",
        "            else:\n",
        "                print(f\"{key}: {value}\")\n",
        "        print(\"-\" * 80)\n",
        "else:\n",
        "    print(\"✗ No news data returned from API\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"NOW FETCHING USING UPDATED StockDataDownloader\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# Now fetch using our updated downloader\n",
        "news_df = downloader.get_recent_news(ticker=ticker, max_items=max_news_items)\n",
        "\n",
        "if news_df is not None:\n",
        "    print(f\"\\n✓ Successfully retrieved {len(news_df)} news items\")\n",
        "    print(f\"✓ Columns: {list(news_df.columns)}\")\n",
        "else:\n",
        "    print(f\"\\n✗ No news found for {ticker}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "NEWS DATA INFO\n",
            "================================================================================\n",
            "\n",
            "Shape: (10, 8)\n",
            "\n",
            "Columns: ['TICKER', 'TITLE', 'PUBLISHER', 'LINK', 'PUBLISH_TIME', 'TYPE', 'THUMBNAIL_URL', 'DOWNLOAD_TIMESTAMP']\n",
            "\n",
            "Data types:\n",
            "TICKER                        object\n",
            "TITLE                         object\n",
            "PUBLISHER                     object\n",
            "LINK                          object\n",
            "PUBLISH_TIME          datetime64[ns]\n",
            "TYPE                          object\n",
            "THUMBNAIL_URL                 object\n",
            "DOWNLOAD_TIMESTAMP    datetime64[ns]\n",
            "dtype: object\n",
            "\n",
            "================================================================================\n",
            "CONTENT CHECK\n",
            "================================================================================\n",
            "\n",
            "First row values:\n",
            "  TICKER: 'NVDA'\n",
            "  TITLE: ''\n",
            "  PUBLISHER: ''\n",
            "  LINK: ''\n",
            "  PUBLISH_TIME: 1969-12-31 19:00:00\n",
            "  TYPE: ''\n",
            "\n",
            "  Empty titles: 10 / 10\n",
            "  Empty links: 10 / 10\n"
          ]
        }
      ],
      "source": [
        "# Display DataFrame info and check for actual content\n",
        "if news_df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"NEWS DATA INFO\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nShape: {news_df.shape}\")\n",
        "    print(f\"\\nColumns: {list(news_df.columns)}\")\n",
        "    print(f\"\\nData types:\")\n",
        "    print(news_df.dtypes)\n",
        "    \n",
        "    # Check if data is actually populated\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CONTENT CHECK\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Check first row to see if we have real data\n",
        "    if len(news_df) > 0:\n",
        "        first_row = news_df.iloc[0]\n",
        "        print(f\"\\nFirst row values:\")\n",
        "        print(f\"  TICKER: '{first_row['TICKER']}'\")\n",
        "        print(f\"  ID: '{first_row['ID']}'\")\n",
        "        print(f\"  TITLE: '{first_row['TITLE']}'\")\n",
        "        print(f\"  SUMMARY: '{first_row['SUMMARY']}'\")\n",
        "        print(f\"  DESCRIPTION: '{first_row['DESCRIPTION']}'\")\n",
        "        print(f\"  PUBLISHER: '{first_row['PUBLISHER']}'\")\n",
        "        print(f\"  LINK: '{first_row['LINK']}'\")\n",
        "        print(f\"  PUBLISH_TIME: {first_row['PUBLISH_TIME']}\")\n",
        "        print(f\"  CONTENT_TYPE: '{first_row['CONTENT_TYPE']}'\")\n",
        "        print(f\"  IS_PREMIUM: {first_row['IS_PREMIUM']}\")\n",
        "        print(f\"  IS_HOSTED: {first_row['IS_HOSTED']}\")\n",
        "        \n",
        "        # Check if all titles are empty\n",
        "        empty_titles = news_df['TITLE'].str.strip() == ''\n",
        "        print(f\"\\n  Empty titles: {empty_titles.sum()} / {len(news_df)}\")\n",
        "        \n",
        "        # Check if all links are empty\n",
        "        empty_links = news_df['LINK'].str.strip() == ''\n",
        "        print(f\"  Empty links: {empty_links.sum()} / {len(news_df)}\")\n",
        "        \n",
        "        # Check if we have summaries\n",
        "        has_summaries = news_df['SUMMARY'].str.strip() != ''\n",
        "        print(f\"  Has summaries: {has_summaries.sum()} / {len(news_df)}\")\n",
        "        \n",
        "        # Check if we have descriptions\n",
        "        has_descriptions = news_df['DESCRIPTION'].str.strip() != ''\n",
        "        print(f\"  Has descriptions: {has_descriptions.sum()} / {len(news_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ALL NEWS ITEMS FOR NVDA\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TICKER</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>LINK</th>\n",
              "      <th>PUBLISH_TIME</th>\n",
              "      <th>TYPE</th>\n",
              "      <th>THUMBNAIL_URL</th>\n",
              "      <th>DOWNLOAD_TIMESTAMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  TICKER TITLE PUBLISHER LINK        PUBLISH_TIME TYPE THUMBNAIL_URL  \\\n",
              "0   NVDA                      1969-12-31 19:00:00                      \n",
              "1   NVDA                      1969-12-31 19:00:00                      \n",
              "2   NVDA                      1969-12-31 19:00:00                      \n",
              "3   NVDA                      1969-12-31 19:00:00                      \n",
              "4   NVDA                      1969-12-31 19:00:00                      \n",
              "5   NVDA                      1969-12-31 19:00:00                      \n",
              "6   NVDA                      1969-12-31 19:00:00                      \n",
              "7   NVDA                      1969-12-31 19:00:00                      \n",
              "8   NVDA                      1969-12-31 19:00:00                      \n",
              "9   NVDA                      1969-12-31 19:00:00                      \n",
              "\n",
              "          DOWNLOAD_TIMESTAMP  \n",
              "0 2025-10-06 16:29:06.517689  \n",
              "1 2025-10-06 16:29:06.517691  \n",
              "2 2025-10-06 16:29:06.517692  \n",
              "3 2025-10-06 16:29:06.517693  \n",
              "4 2025-10-06 16:29:06.517693  \n",
              "5 2025-10-06 16:29:06.517694  \n",
              "6 2025-10-06 16:29:06.517695  \n",
              "7 2025-10-06 16:29:06.517696  \n",
              "8 2025-10-06 16:29:06.517697  \n",
              "9 2025-10-06 16:29:06.517698  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display all news items with full text content\n",
        "if news_df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"ALL NEWS ITEMS FOR {ticker} - FULL CONTENT\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Set pandas display options to show full content\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_colwidth', 200)  # Show more text\n",
        "    pd.set_option('display.width', None)\n",
        "    \n",
        "    # Show key columns for full-text database\n",
        "    key_columns = ['ID', 'TITLE', 'SUMMARY', 'DESCRIPTION', 'PUBLISHER', 'LINK', 'PUBLISH_TIME', 'CONTENT_TYPE']\n",
        "    display(news_df[key_columns])\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"FULL TEXT CONTENT FOR DATABASE\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Show the full text content that would go into a full-text database\n",
        "    for idx, row in news_df.iterrows():\n",
        "        print(f\"\\n[{idx + 1}] ID: {row['ID']}\")\n",
        "        print(f\"    TITLE: {row['TITLE']}\")\n",
        "        print(f\"    SUMMARY: {row['SUMMARY']}\")\n",
        "        print(f\"    DESCRIPTION: {row['DESCRIPTION']}\")\n",
        "        print(f\"    PUBLISHER: {row['PUBLISHER']}\")\n",
        "        print(f\"    CONTENT_TYPE: {row['CONTENT_TYPE']}\")\n",
        "        print(f\"    PUBLISH_TIME: {row['PUBLISH_TIME']}\")\n",
        "        print(f\"    LINK: {row['LINK']}\")\n",
        "        print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "FORMATTED NEWS FOR NVDA\n",
            "================================================================================\n",
            "\n",
            "[1] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[2] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[3] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[4] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[5] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[6] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[7] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[8] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[9] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[10] \n",
            "    Publisher: \n",
            "    Published: 1969-12-31 19:00:00\n",
            "    Type: \n",
            "    Link: \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Display news in a more readable format with all text content\n",
        "if news_df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"FORMATTED NEWS FOR {ticker} - READABLE FORMAT\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    for idx, row in news_df.iterrows():\n",
        "        print(f\"\\n[{idx + 1}] {row['TITLE']}\")\n",
        "        print(f\"    ID: {row['ID']}\")\n",
        "        print(f\"    Summary: {row['SUMMARY']}\")\n",
        "        print(f\"    Description: {row['DESCRIPTION']}\")\n",
        "        print(f\"    Publisher: {row['PUBLISHER']}\")\n",
        "        print(f\"    Published: {row['PUBLISH_TIME']}\")\n",
        "        print(f\"    Content Type: {row['CONTENT_TYPE']}\")\n",
        "        print(f\"    Is Premium: {row['IS_PREMIUM']}\")\n",
        "        print(f\"    Is Hosted: {row['IS_HOSTED']}\")\n",
        "        print(f\"    Link: {row['LINK']}\")\n",
        "        if row['THUMBNAIL_URL']:\n",
        "            print(f\"    Thumbnail: {row['THUMBNAIL_URL']}\")\n",
        "        print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY STATISTICS\n",
            "================================================================================\n",
            "\n",
            "News items by publisher:\n",
            "  : 10\n",
            "\n",
            "News items by type:\n",
            "  : 10\n",
            "\n",
            "Date range:\n",
            "  Earliest: 1969-12-31 19:00:00\n",
            "  Latest: 1969-12-31 19:00:00\n",
            "\n",
            "Items with thumbnails: 0 / 10\n"
          ]
        }
      ],
      "source": [
        "# Display summary statistics\n",
        "if news_df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SUMMARY STATISTICS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Count by publisher\n",
        "    print(\"\\nNews items by publisher:\")\n",
        "    publisher_counts = news_df['PUBLISHER'].value_counts()\n",
        "    for publisher, count in publisher_counts.items():\n",
        "        print(f\"  {publisher}: {count}\")\n",
        "    \n",
        "    # Count by content type\n",
        "    print(\"\\nNews items by content type:\")\n",
        "    type_counts = news_df['CONTENT_TYPE'].value_counts()\n",
        "    for news_type, count in type_counts.items():\n",
        "        print(f\"  {news_type}: {count}\")\n",
        "    \n",
        "    # Count by premium status\n",
        "    print(\"\\nNews items by premium status:\")\n",
        "    premium_counts = news_df['IS_PREMIUM'].value_counts()\n",
        "    for is_premium, count in premium_counts.items():\n",
        "        print(f\"  Premium: {is_premium} - {count} items\")\n",
        "    \n",
        "    # Date range\n",
        "    print(f\"\\nDate range:\")\n",
        "    print(f\"  Earliest: {news_df['PUBLISH_TIME'].min()}\")\n",
        "    print(f\"  Latest: {news_df['PUBLISH_TIME'].max()}\")\n",
        "    \n",
        "    # Check for thumbnails\n",
        "    has_thumbnail = news_df['THUMBNAIL_URL'].notna() & (news_df['THUMBNAIL_URL'] != '')\n",
        "    print(f\"\\nItems with thumbnails: {has_thumbnail.sum()} / {len(news_df)}\")\n",
        "    \n",
        "    # Text content statistics\n",
        "    print(f\"\\nText content statistics:\")\n",
        "    has_titles = news_df['TITLE'].str.strip() != ''\n",
        "    has_summaries = news_df['SUMMARY'].str.strip() != ''\n",
        "    has_descriptions = news_df['DESCRIPTION'].str.strip() != ''\n",
        "    print(f\"  Items with titles: {has_titles.sum()} / {len(news_df)}\")\n",
        "    print(f\"  Items with summaries: {has_summaries.sum()} / {len(news_df)}\")\n",
        "    print(f\"  Items with descriptions: {has_descriptions.sum()} / {len(news_df)}\")\n",
        "    \n",
        "    # Average text lengths\n",
        "    if has_titles.any():\n",
        "        avg_title_length = news_df[has_titles]['TITLE'].str.len().mean()\n",
        "        print(f\"  Average title length: {avg_title_length:.1f} characters\")\n",
        "    if has_summaries.any():\n",
        "        avg_summary_length = news_df[has_summaries]['SUMMARY'].str.len().mean()\n",
        "        print(f\"  Average summary length: {avg_summary_length:.1f} characters\")\n",
        "    if has_descriptions.any():\n",
        "        avg_desc_length = news_df[has_descriptions]['DESCRIPTION'].str.len().mean()\n",
        "        print(f\"  Average description length: {avg_desc_length:.1f} characters\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:06,546 - app - INFO - Fetching recent news for AAPL (attempt 1/3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TESTING MULTIPLE TICKERS\n",
            "================================================================================\n",
            "\n",
            "Fetching news for AAPL...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:06,866 - app - INFO - Successfully fetched 5 news items for AAPL\n",
            "2025-10-06 16:29:06,866 - app - INFO - Fetching recent news for MSFT (attempt 1/3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✓ Retrieved 5 items\n",
            "  Latest: ...\n",
            "\n",
            "Fetching news for MSFT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:07,073 - app - INFO - Successfully fetched 5 news items for MSFT\n",
            "2025-10-06 16:29:07,073 - app - INFO - Fetching recent news for GOOGL (attempt 1/3)\n",
            "2025-10-06 16:29:07,273 - app - INFO - Successfully fetched 5 news items for GOOGL\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✓ Retrieved 5 items\n",
            "  Latest: ...\n",
            "\n",
            "Fetching news for GOOGL...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:07,275 - app - INFO - Fetching recent news for TSLA (attempt 1/3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✓ Retrieved 5 items\n",
            "  Latest: ...\n",
            "\n",
            "Fetching news for TSLA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:07,475 - app - INFO - Successfully fetched 5 news items for TSLA\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✓ Retrieved 5 items\n",
            "  Latest: ...\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "AAPL: 5 news items\n",
            "MSFT: 5 news items\n",
            "GOOGL: 5 news items\n",
            "TSLA: 5 news items\n"
          ]
        }
      ],
      "source": [
        "# Test with multiple tickers\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TESTING MULTIPLE TICKERS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "test_tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\"]\n",
        "results = {}\n",
        "\n",
        "for test_ticker in test_tickers:\n",
        "    print(f\"\\nFetching news for {test_ticker}...\")\n",
        "    df = downloader.get_recent_news(ticker=test_ticker, max_items=5)\n",
        "    \n",
        "    if df is not None:\n",
        "        results[test_ticker] = len(df)\n",
        "        print(f\"  ✓ Retrieved {len(df)} items\")\n",
        "        # Show first headline\n",
        "        if len(df) > 0:\n",
        "            print(f\"  Latest: {df.iloc[0]['TITLE'][:80]}...\")\n",
        "    else:\n",
        "        results[test_ticker] = 0\n",
        "        print(f\"  ✗ No news found\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "for ticker_name, count in results.items():\n",
        "    print(f\"{ticker_name}: {count} news items\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 16:29:07,486 - app - INFO - Loaded 1 existing records for NVDA\n",
            "2025-10-06 16:29:07,487 - app - INFO - Merging 10 new records with 1 existing records\n",
            "2025-10-06 16:29:07,488 - app - INFO - Removed 10 duplicate news items\n",
            "2025-10-06 16:29:07,492 - app - INFO - Successfully saved 1 total records to data/price-history/NVDA/news-NVDA.parquet\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SAVE NEWS TO FILE\n",
            "================================================================================\n",
            "\n",
            "✓ News data saved successfully!\n",
            "  Location: ./data/news/NVDA/news-NVDA.parquet\n",
            "  Records: 10\n"
          ]
        }
      ],
      "source": [
        "# Save the news to a parquet file\n",
        "if news_df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SAVE NEWS TO FILE\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Save the data to ./data/news/{ticker}/news-{ticker}.parquet\n",
        "    success = downloader.format_and_save_data(news_df, ticker, data_type=\"news\")\n",
        "    \n",
        "    if success:\n",
        "        print(f\"\\n✓ News data saved successfully!\")\n",
        "        \n",
        "        # Get the full absolute path\n",
        "        import os\n",
        "        filepath = f\"./data/news/{ticker}/news-{ticker}.parquet\"\n",
        "        abs_filepath = os.path.abspath(filepath)\n",
        "        \n",
        "        print(f\"  Location: {filepath}\")\n",
        "        print(f\"  Full Path: {abs_filepath}\")\n",
        "        print(f\"  Records: {len(news_df)}\")\n",
        "        \n",
        "        # Check if there were any existing records\n",
        "        if os.path.exists(filepath):\n",
        "            saved_df = pd.read_parquet(filepath)\n",
        "            print(f\"  Total records in file: {len(saved_df)}\")\n",
        "            \n",
        "            # Show the schema of the saved file\n",
        "            print(f\"\\n  Schema of saved file:\")\n",
        "            print(f\"    Columns: {list(saved_df.columns)}\")\n",
        "            print(f\"    Data types:\")\n",
        "            for col, dtype in saved_df.dtypes.items():\n",
        "                print(f\"      {col}: {dtype}\")\n",
        "            \n",
        "            # Show sample of saved data\n",
        "            print(f\"\\n  Sample of saved data:\")\n",
        "            sample_cols = ['ID', 'TITLE', 'SUMMARY', 'PUBLISHER', 'CONTENT_TYPE']\n",
        "            print(saved_df[sample_cols].head(2).to_string())\n",
        "            \n",
        "    else:\n",
        "        print(f\"\\n✗ Failed to save news data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create full-text database schema and sample\n",
        "if news_df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FULL-TEXT DATABASE SCHEMA\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Define the full-text database schema\n",
        "    full_text_schema = {\n",
        "        'id': 'VARCHAR(36) PRIMARY KEY',  # UUID\n",
        "        'ticker': 'VARCHAR(10)',\n",
        "        'title': 'TEXT',\n",
        "        'summary': 'TEXT', \n",
        "        'description': 'TEXT',\n",
        "        'full_text': 'TEXT',  # Combined searchable text\n",
        "        'publisher': 'VARCHAR(100)',\n",
        "        'content_type': 'VARCHAR(50)',\n",
        "        'publish_time': 'TIMESTAMP',\n",
        "        'is_premium': 'BOOLEAN',\n",
        "        'link': 'VARCHAR(1000)',\n",
        "        'thumbnail_url': 'VARCHAR(1000)',\n",
        "        'download_timestamp': 'TIMESTAMP'\n",
        "    }\n",
        "    \n",
        "    print(\"Full-text database schema:\")\n",
        "    for field, data_type in full_text_schema.items():\n",
        "        print(f\"  {field}: {data_type}\")\n",
        "    \n",
        "    # Create sample full-text records\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SAMPLE FULL-TEXT RECORDS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    for idx, row in news_df.head(3).iterrows():\n",
        "        # Combine all text fields for full-text search\n",
        "        full_text = f\"{row['TITLE']} {row['SUMMARY']} {row['DESCRIPTION']}\".strip()\n",
        "        \n",
        "        print(f\"\\nRecord {idx + 1}:\")\n",
        "        print(f\"  ID: {row['ID']}\")\n",
        "        print(f\"  Ticker: {row['TICKER']}\")\n",
        "        print(f\"  Title: {row['TITLE']}\")\n",
        "        print(f\"  Summary: {row['SUMMARY']}\")\n",
        "        print(f\"  Description: {row['DESCRIPTION']}\")\n",
        "        print(f\"  Full Text (for search): {full_text[:200]}...\")\n",
        "        print(f\"  Publisher: {row['PUBLISHER']}\")\n",
        "        print(f\"  Content Type: {row['CONTENT_TYPE']}\")\n",
        "        print(f\"  Publish Time: {row['PUBLISH_TIME']}\")\n",
        "        print(f\"  Is Premium: {row['IS_PREMIUM']}\")\n",
        "        print(f\"  Link: {row['LINK']}\")\n",
        "        print(\"-\" * 80)\n",
        "    \n",
        "    # Show SQL for creating full-text search table\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SQL FOR FULL-TEXT SEARCH TABLE\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    sql_create = \"\"\"\n",
        "CREATE TABLE stock_news_fulltext (\n",
        "    id VARCHAR(36) PRIMARY KEY,\n",
        "    ticker VARCHAR(10),\n",
        "    title TEXT,\n",
        "    summary TEXT,\n",
        "    description TEXT,\n",
        "    full_text TEXT,\n",
        "    publisher VARCHAR(100),\n",
        "    content_type VARCHAR(50),\n",
        "    publish_time TIMESTAMP,\n",
        "    is_premium BOOLEAN,\n",
        "    link VARCHAR(1000),\n",
        "    thumbnail_url VARCHAR(1000),\n",
        "    download_timestamp TIMESTAMP,\n",
        "    \n",
        "    -- Full-text search index\n",
        "    FULLTEXT(title, summary, description, full_text)\n",
        ");\n",
        "\"\"\"\n",
        "    print(sql_create)\n",
        "    \n",
        "    # Show sample INSERT statements\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SAMPLE INSERT STATEMENTS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    for idx, row in news_df.head(2).iterrows():\n",
        "        full_text = f\"{row['TITLE']} {row['SUMMARY']} {row['DESCRIPTION']}\".strip()\n",
        "        \n",
        "        insert_sql = f\"\"\"\n",
        "INSERT INTO stock_news_fulltext VALUES (\n",
        "    '{row['ID']}',\n",
        "    '{row['TICKER']}',\n",
        "    '{row['TITLE'].replace(\"'\", \"''\")}',\n",
        "    '{row['SUMMARY'].replace(\"'\", \"''\")}',\n",
        "    '{row['DESCRIPTION'].replace(\"'\", \"''\")}',\n",
        "    '{full_text.replace(\"'\", \"''\")}',\n",
        "    '{row['PUBLISHER']}',\n",
        "    '{row['CONTENT_TYPE']}',\n",
        "    '{row['PUBLISH_TIME']}',\n",
        "    {row['IS_PREMIUM']},\n",
        "    '{row['LINK']}',\n",
        "    '{row['THUMBNAIL_URL']}',\n",
        "    '{row['DOWNLOAD_TIMESTAMP']}'\n",
        ");\n",
        "\"\"\"\n",
        "        print(insert_sql)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "newsFile = \"/Users/jdacosta/Library/CloudStorage/GoogleDrive-john.dacosta@snowflake.com/My Drive/_local/Downloads/_cursor_demos/Snowflake_Intelligence_HOL/jdacosta/pricehistory/data/price-history/NVDA/news-NVDA.parquet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfNews = pd.read_parquet(newsFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TICKER</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>LINK</th>\n",
              "      <th>PUBLISH_TIME</th>\n",
              "      <th>TYPE</th>\n",
              "      <th>THUMBNAIL_URL</th>\n",
              "      <th>DOWNLOAD_TIMESTAMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NVDA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1969-12-31 19:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2025-10-06 16:29:06.517698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  TICKER TITLE PUBLISHER LINK        PUBLISH_TIME TYPE THUMBNAIL_URL  \\\n",
              "0   NVDA                      1969-12-31 19:00:00                      \n",
              "\n",
              "          DOWNLOAD_TIMESTAMP  \n",
              "0 2025-10-06 16:29:06.517698  "
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfNews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
